{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prototype 1\n",
    "\n",
    "This prototype will just test the basic functionality of the broadcast and live youtube instruction loop. Very minimal prototype. Live is initiated manually using OBS, the live chat is then scraped using pytchat, the live chat (numbers 1-5) is then used to pick which video to play using opencv. The video is then broadcast live to youtube via OBS as a closed loop with a slight delay. \n",
    "\n",
    "There is code to try to automate the broadcast using OBS websocket, but authentication is required manually anyways, so it's just easier to start the broadcast manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:18:58 [Ayush]- :moai:\n",
      "2023-08-16 18:18:59 [kim lilly üòç]- devil 10th pachi ni life barbadd na dost na pyaar:rolling_on_the_floor_laughing::rolling_on_the_floor_laughing:\n",
      "2023-08-16 18:19:00 [Moinnnnnnn]- #Jasmine , ihy\n",
      "2023-08-16 18:19:01 [Devil_]- #kim lilly naresh chomu chhe :face_with_tears_of_joy: ana jode vat na kar :rolling_on_the_floor_laughing:\n"
     ]
    }
   ],
   "source": [
    "# get live chat\n",
    "\n",
    "import pytchat\n",
    "# test lofi girl live\n",
    "# https://www.youtube.com/watch?v=jfKfPfyJRdk\n",
    "\n",
    "# test moonrabbit: https://www.youtube.com/watch?v=op_CtC7mJms\n",
    "\n",
    "chat = pytchat.create(video_id=\"jfKfPfyJRdk\")\n",
    "while chat.is_alive():\n",
    "    for c in chat.get().sync_items():\n",
    "        print(f\"{c.datetime} [{c.author.name}]- {c.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# testing playing video with choice - choices are numbers 1-5\n",
    "\n",
    "def make_videos_dict():\n",
    "    # files = glob.glob('/Volumes/My Passport/UAL_Thesis/raw_videos/*')\n",
    "    files = glob.glob('G:/UAL_Thesis/raw_videos/*')\n",
    "    files = [f.split('/')[-1] for f in files]\n",
    "    files_dict = {str(i+1): value for i, value in enumerate(files)}\n",
    "\n",
    "    return files_dict\n",
    "  \n",
    "def test_choose_videos(i , videos_dict):\n",
    "    return videos_dict[i]\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# play video according to live chat command using cv2 \n",
    "# raw_videos_path = '/Volumes/My Passport/UAL_Thesis/raw_videos'\n",
    "raw_videos_path = 'G:/UAL_Thesis/raw_videos/*'\n",
    "videos_dict = make_videos_dict()\n",
    "\n",
    "def play_video(video_path, play_time=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "    while(cap.isOpened() and time.time() - start_time < play_time):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imshow('Frame', frame)\n",
    "            # Press Q on keyboard to exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     video_file_input = input(\"Enter the video file path choice to play or 'q' to quit: \")\n",
    "#     if video_file_input.lower() == 'q':\n",
    "#         break\n",
    "#     else:\n",
    "#         video_file = raw_videos_path + '/'+test_choose_videos(video_file_input, videos_dict)\n",
    "#         print(video_file)\n",
    "#         play_video(video_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16 18:43:45 [Moon Rabbit]- 1\n",
      "G:/UAL_Thesis/raw_videos\\idle_bob_1.MOV\n",
      "2023-08-16 18:45:37 [Moon Rabbit]- 3\n",
      "G:/UAL_Thesis/raw_videos\\jump_out_in.MOV\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# choose videos using live chat\n",
    "\n",
    "# video_id = \n",
    "import pytchat\n",
    "# windows\n",
    "raw_videos_path = 'G:/UAL_Thesis' \n",
    "\n",
    "# live stream must start first, then copy the id from the live stream URL\n",
    "chat = pytchat.create(video_id=\"zKsdVr4yo2s\")\n",
    "while chat.is_alive():\n",
    "    for c in chat.get().sync_items():\n",
    "        print(f\"{c.datetime} [{c.author.name}]- {c.message}\")\n",
    "        video_file = raw_videos_path + '/'+test_choose_videos(c.message, videos_dict)\n",
    "        print(video_file)\n",
    "        play_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "\n",
    "# Load the ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('auth.ini')\n",
    "\n",
    "# Access the values using the section and key\n",
    "port = int(config['OBS Credentials']['port'])\n",
    "host = config['OBS Credentials']['host']\n",
    "pwd = config['OBS Credentials']['pwd']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test obs websocket - it works but, it's not needed really, it's easier and more robust to just start the stream manually\n",
    "\n",
    "import cv2\n",
    "import pytchat\n",
    "from obswebsocket import obsws, requests\n",
    "import pygetwindow as gw\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# Connect to OBS - requires AUTH file\n",
    "\n",
    "ws = obsws(host, port,pwd)\n",
    "ws.connect()\n",
    "\n",
    "\n",
    "\n",
    "# don't forget to manually select the live stream in OBS first before starting to stream\n",
    "# also stream will not be present if previous livestream edit window is not closed on youtube studios\n",
    "\n",
    "    # Start streaming\n",
    "ws.call(requests.StartStreaming())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebSocketAddressException",
     "evalue": "[Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\site-packages\\websocket\\_http.py:145\u001b[0m, in \u001b[0;36m_get_addrinfo_list\u001b[1;34m(hostname, port, is_secure, proxy)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m phost:\n\u001b[1;32m--> 145\u001b[0m     addrinfo_list \u001b[39m=\u001b[39m socket\u001b[39m.\u001b[39;49mgetaddrinfo(\n\u001b[0;32m    146\u001b[0m         hostname, port, \u001b[39m0\u001b[39;49m, socket\u001b[39m.\u001b[39;49mSOCK_STREAM, socket\u001b[39m.\u001b[39;49mSOL_TCP)\n\u001b[0;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m addrinfo_list, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebSocketAddressException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39m# Connect to OBS\u001b[39;00m\n\u001b[0;32m     12\u001b[0m ws \u001b[39m=\u001b[39m obsws(host,port,pwd)\n\u001b[1;32m---> 13\u001b[0m ws\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m     15\u001b[0m \u001b[39m# List all profiles (broadcasts)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# current_settings = ws.call(requests.GetStreamSettings())\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# print(current_settings)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[39m# create scene\u001b[39;00m\n\u001b[0;32m     20\u001b[0m scene_request \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mCreateScene()\n",
      "File \u001b[1;32mc:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\site-packages\\obswebsocket\\core.py:84\u001b[0m, in \u001b[0;36mobsws.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mws://\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport)\n\u001b[0;32m     83\u001b[0m LOG\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mConnecting to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (url))\n\u001b[1;32m---> 84\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mws\u001b[39m.\u001b[39;49mconnect(url)\n\u001b[0;32m     85\u001b[0m LOG\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mConnected!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlegacy:\n",
      "File \u001b[1;32mc:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\site-packages\\websocket\\_core.py:248\u001b[0m, in \u001b[0;36mWebSocket.connect\u001b[1;34m(self, url, **options)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mConnect to url. url is websocket url scheme.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[39mie. ws://host:port/resource\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39m            pre-initialized stream socket.\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock_opt\u001b[39m.\u001b[39mtimeout \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock_opt\u001b[39m.\u001b[39mtimeout)\n\u001b[1;32m--> 248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, addrs \u001b[39m=\u001b[39m connect(url, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msock_opt, proxy_info(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions),\n\u001b[0;32m    249\u001b[0m                            options\u001b[39m.\u001b[39;49mpop(\u001b[39m'\u001b[39;49m\u001b[39msocket\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m))\n\u001b[0;32m    251\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandshake_response \u001b[39m=\u001b[39m handshake(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock, \u001b[39m*\u001b[39maddrs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\site-packages\\websocket\\_http.py:112\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(url, options, proxy, socket)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m socket:\n\u001b[0;32m    110\u001b[0m     \u001b[39mreturn\u001b[39;00m socket, (hostname, port, resource)\n\u001b[1;32m--> 112\u001b[0m addrinfo_list, need_tunnel, auth \u001b[39m=\u001b[39m _get_addrinfo_list(\n\u001b[0;32m    113\u001b[0m     hostname, port, is_secure, proxy)\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m addrinfo_list:\n\u001b[0;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m WebSocketException(\n\u001b[0;32m    116\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mHost not found.: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m hostname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(port))\n",
      "File \u001b[1;32mc:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\site-packages\\websocket\\_http.py:157\u001b[0m, in \u001b[0;36m_get_addrinfo_list\u001b[1;34m(hostname, port, is_secure, proxy)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[39mreturn\u001b[39;00m addrinfo_list, \u001b[39mTrue\u001b[39;00m, pauth\n\u001b[0;32m    156\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mraise\u001b[39;00m WebSocketAddressException(e)\n",
      "\u001b[1;31mWebSocketAddressException\u001b[0m: [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "# prototype-1\n",
    "# Have to run it twice, once to start the OBS stream, then copy the video id from the started stream to scrape the chat, then run again for it to work.\n",
    "# As said, it works, but still requires manual authorisation in OBS, so might as well just start the stream manually and save maintaining all this OBS code.\n",
    "# live stream url: https://youtu.be/nPdEhg5zNMU\n",
    "\n",
    "import cv2\n",
    "import pytchat\n",
    "from obswebsocket import obsws, requests\n",
    "import pygetwindow as gw\n",
    "import time\n",
    "\n",
    "# Connect to OBS\n",
    "\n",
    "ws = obsws(host,port,pwd)\n",
    "ws.connect()\n",
    "\n",
    "# List all profiles (broadcasts)\n",
    "# current_settings = ws.call(requests.GetStreamSettings())\n",
    "# print(current_settings)\n",
    "\n",
    "# create scene\n",
    "scene_request = requests.CreateScene()\n",
    "scene_request.scene_name = \"OpenCV_Scene\"\n",
    "scene_name =  \"OpenCV_Scene\"\n",
    "ws.call(scene_request)\n",
    "\n",
    "\n",
    "# Add a \"Window Capture\" source to the scene\n",
    "source_name = \"OpenCV_Window_Capture\"\n",
    "window_name = \"Frame\"  # Name of the OpenCV window (as per cv2.imshow('Frame', frame))\n",
    "source_request = requests.CreateSource()\n",
    "source_request.sourceName = source_name\n",
    "source_request.sourceType = \"window_capture\"\n",
    "source_request.sourceSettings = {\n",
    "    \"window\": window_name + \":.*\",  # This regex ensures it matches the window title even if there are additional characters\n",
    "    \"window_match_priority\": 1  # Match by window title\n",
    "}\n",
    "ws.call(source_request)\n",
    "\n",
    "# Add the created source to the scene\n",
    "ws.call(requests.AddSceneItem(scene_name, source_name, -1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# don't forget to manually select the live stream in OBS first before starting to stream\n",
    "# also stream will not be present if previous livestream edit window is not closed on youtube studios\n",
    "\n",
    "    # Start streaming\n",
    "ws.call(requests.StartStreaming())\n",
    "\n",
    "\n",
    "\n",
    "chat = pytchat.create(video_id=\"nPdEhg5zNMU\")\n",
    "while chat.is_alive():\n",
    "    for c in chat.get().sync_items():\n",
    "        print(f\"{c.datetime} [{c.author.name}]- {c.message}\")\n",
    "        video_file = raw_videos_path + '/'+test_choose_videos(c.message, videos_dict)\n",
    "        print(video_file)\n",
    "        play_video(video_file)\n",
    "\n",
    "ws.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive_dance_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
