{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototpye 4 Intermediate - Using MEED dataset in a transformer\n",
    "\n",
    "Use normalised keypoint values in a transformer.\n",
    "\n",
    "Adding emotional encoding. This is how it is going to work. Encoded emotions is going to be added to each frame, so that model is more flexible during generation.\n",
    "\n",
    "!The starting input is currently 1 long list of coords. But be careful because model might learn the transition between 1 video to another which is erroneous\n",
    "\n",
    "Front videos only.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\n"
     ]
    }
   ],
   "source": [
    "# set up environment\n",
    "import glob\n",
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Set root directory\n",
    "root_dir = \"C:\\\\Users\\\\avika\\\\OneDrive\\\\Documents\\\\UAL\\\\interactive_dance_thesis\"\n",
    "os.chdir(root_dir)\n",
    "\n",
    "# Check if the current working directory was set correctly\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1326/1326 [00:08<00:00, 160.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1326\n",
      "1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "from typing import List\n",
    "\n",
    "logger = logging.getLogger()\n",
    "# Clear previous handlers\n",
    "for handler in logger.handlers[:]:\n",
    "    handler.close()\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "logging.basicConfig(filename= f\"preprocessing_log.txt\", level=logging.INFO, filemode='w')\n",
    "# logging clear file\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def interpolate(coord_prev, coord_next):\n",
    "    \"\"\"\n",
    "    Linearly interpolate between two coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    - coord_prev (float): Coordinate of the previous frame.\n",
    "    - coord_next (float): Coordinate of the next frame.\n",
    "\n",
    "    Returns:\n",
    "    - (float): Interpolated coordinate.\n",
    "    \"\"\"\n",
    "    return (coord_prev + coord_next) / 2\n",
    "\n",
    "def preprocess_data(files: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Pre-process data by interpolating to avoid (0,0) keypoints.\n",
    "\n",
    "    Parameters:\n",
    "    - files (List[str]): List of file paths to process.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Pre-processed data.\n",
    "    \"\"\"\n",
    "    x_list=[]\n",
    "    y_list=[]\n",
    "    conf_list=[]\n",
    "    emotions = []\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "            x = data['x']\n",
    "            y = data['y']\n",
    "            conf = data['confidence']\n",
    "            emotions.extend(files[0].split('_')[-2].split('\\\\')[0][3:-3])\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                # Check if coordinate is (0,0)\n",
    "                if x[i] == 0 and y[i] == 0:\n",
    "                    # logger.info(f\"Found (0,0) at index {i} in file {file}\")\n",
    "                    # If first frame, copy from next frame\n",
    "                    if i == 0:\n",
    "                        j = i + 1\n",
    "                        # Find next non-(0,0) frame\n",
    "                        while x[j] == 0 and y[j] == 0:\n",
    "                            j += 1\n",
    "                        x[i] = x[j]\n",
    "                        y[i] = y[j]\n",
    "                    # If last frame, copy from previous frame\n",
    "                    elif i == len(x) - 1:\n",
    "                        x[i] = x[i-1]\n",
    "                        y[i] = y[i-1]\n",
    "                    # For a frame in the middle\n",
    "                    else:\n",
    "                        # Find the next non-(0,0) frame\n",
    "                        j = i + 1\n",
    "                        while j < len(x) and x[j] == 0 and y[j] == 0:\n",
    "                            j += 1\n",
    "                        # If no non-(0,0) frame found, use the previous frame, otherwise interpolate\n",
    "                        if j == len(x):\n",
    "                            x[i] = x[i-1]\n",
    "                            y[i] = y[i-1]\n",
    "                        else:\n",
    "                            x[i] = interpolate(x[i-1], x[j])\n",
    "                            y[i] = interpolate(y[i-1], y[j])\n",
    "            \n",
    "            x_list.append(x)\n",
    "            y_list.append(y)\n",
    "            conf_list.append(conf)\n",
    "\n",
    "    return {\"x\": x_list, \"y\": y_list, \"confidence\": conf_list, \"emotions\": emotions}\n",
    "\n",
    "\n",
    "files = glob.glob(\"G:/UAL_Thesis/affective_computing_datasets/multiview-emotional-expressions-dataset/*/front_*/processed_data.json\")\n",
    "processed_data = preprocess_data(files)\n",
    "x_list = processed_data['x']\n",
    "y_list = processed_data['y']\n",
    "conf_list = processed_data['confidence']\n",
    "emotions_labels = processed_data['emotions']\n",
    "\n",
    "print(len(x_list))\n",
    "print(len(emotions_labels))\n",
    "# shape [num_frames, keypoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('A',Anger,'D',Disgust,'F',Fear,'H',Happiness,'N',Neutral,'SA',Sad,'SU',Surprise);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are still 0,0 coordinates\n",
    "\n",
    "for i in range(len(x_list)):\n",
    "    for j in range(len(x_list[i])):\n",
    "        if x_list[i][j] == 0 and y_list[i][j] == 0:\n",
    "            print(i,j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_values_2D(frames):\n",
    "    \"\"\"\n",
    "    Takes in a list of lists (frames), returns max and min values and normalized list\n",
    "    \n",
    "    Parameters:\n",
    "        frames: List of lists containing keypoints for each frame.\n",
    "    \n",
    "    Returns:\n",
    "        max_val: Maximum keypoint value across all frames.\n",
    "        min_val: Minimum keypoint value across all frames.\n",
    "        normalized_frames: Normalized keypoints for each frame.\n",
    "    \"\"\"\n",
    "    # Flatten the data to find global min and max\n",
    "    flat_data = [kp for frame in frames for kp in frame]\n",
    "    max_val = max(flat_data)\n",
    "    min_val = min(flat_data)\n",
    "    \n",
    "    # Normalize data\n",
    "    normalized_frames = [\n",
    "        [2 * (kp - min_val) / (max_val - min_val) - 1 for kp in frame]\n",
    "        for frame in frames\n",
    "    ]\n",
    "    \n",
    "    return max_val, min_val, normalized_frames\n",
    "\n",
    "max_x, min_x, normalised_x = normalize_values_2D(x_list)\n",
    "max_y, min_y, normalised_y = normalize_values_2D(y_list)\n",
    "len(normalised_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # create 1D array of 50 numbers (x,y,x,y --> 25 keypoints) for each frame\n",
    "# all_frames = []\n",
    "# n_parts = 25\n",
    "\n",
    "# for i in tqdm(range(0, len(x_list), n_parts)):\n",
    "#     frame_data = [coord for pair in zip(x_list[i:i+n_parts], y_list[i:i+n_parts]) for coord in pair]\n",
    "#     all_frames.append(frame_data)\n",
    "\n",
    "# data has 0s - need to ignore\n",
    "\n",
    "def visualise_skeleton(all_frames, max_x, max_y, max_frames=500, save=False, save_path=None, prefix=None):\n",
    "    \n",
    "    \"\"\"Input all frames dim 50xn n being the number of frames 50= 25 keypoints x and y coordinates\"\"\"\n",
    "\n",
    "    \n",
    "    # visualise to check if the data is correct\n",
    "    # BODY_25 Keypoints\n",
    "    keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', \n",
    "                        'L-Elb', 'L-Wr', 'MidHip', 'R-Hip', 'R-Knee', 'R-Ank', \n",
    "                        'L-Hip', 'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', \n",
    "                        'L-Ear', 'L-BigToe', 'L-SmallToe', 'L-Heel', 'R-BigToe', \n",
    "                        'R-SmallToe', 'R-Heel']\n",
    "\n",
    "\n",
    "    limb_connections = [\n",
    "        (\"Nose\", \"Neck\"),\n",
    "        (\"Neck\", \"R-Sho\"),\n",
    "        (\"R-Sho\", \"R-Elb\"),\n",
    "        (\"R-Elb\", \"R-Wr\"),\n",
    "        (\"Neck\", \"L-Sho\"),\n",
    "        (\"L-Sho\", \"L-Elb\"),\n",
    "        (\"L-Elb\", \"L-Wr\"),\n",
    "        (\"Neck\", \"MidHip\"),\n",
    "        (\"MidHip\", \"R-Hip\"),\n",
    "        (\"R-Hip\", \"R-Knee\"),\n",
    "        (\"R-Knee\", \"R-Ank\"),\n",
    "        (\"MidHip\", \"L-Hip\"),\n",
    "        (\"L-Hip\", \"L-Knee\"),\n",
    "        (\"L-Knee\", \"L-Ank\"),\n",
    "        (\"Nose\", \"R-Eye\"),\n",
    "        (\"R-Eye\", \"R-Ear\"),\n",
    "        (\"Nose\", \"L-Eye\"),\n",
    "        (\"L-Eye\", \"L-Ear\"),\n",
    "        (\"L-Ank\", \"L-BigToe\"),\n",
    "        (\"L-Ank\", \"L-SmallToe\"),\n",
    "        (\"L-Ank\", \"L-Heel\"),\n",
    "        (\"R-Ank\", \"R-BigToe\"),\n",
    "        (\"R-Ank\", \"R-SmallToe\"),\n",
    "        (\"R-Ank\", \"R-Heel\")\n",
    "    ]\n",
    "    \n",
    "     # Define a mapping from emotion vectors to emotion labels\n",
    "    # Define emotion labels\n",
    "    emotion_labels = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sad', 'Surprise']\n",
    "    \n",
    "    # Initialize a blank canvas (image)\n",
    "    canvas_size = (int(max_y)+50, int(max_x)+50, 3)  \n",
    "    canvas = np.zeros(canvas_size, dtype=np.uint8)\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    if save:\n",
    "        # Determine the save path\n",
    "        if save_path is None:\n",
    "            save_path = \"D:\\\\Interactive Dance Thesis Tests\\\\TransformerResults\"\n",
    "\n",
    "        # Ensure directory exists\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "\n",
    "        # Determine a unique filename\n",
    "        existing_files = os.listdir(save_path)\n",
    "        file_num = 1\n",
    "        while f\"{prefix or ''}{file_num}.mp4\" in existing_files:\n",
    "            file_num += 1\n",
    "        out_path = os.path.join(save_path, f\"{prefix or ''}{file_num}.mp4\")\n",
    "\n",
    "        # Create the video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(out_path, fourcc, 10.0, (canvas_size[1], canvas_size[0]))\n",
    "\n",
    "    # Iterate over every frame\n",
    "    for frame_data in all_frames[:max_frames]:\n",
    "        canvas_copy = canvas.copy()\n",
    "\n",
    "        # Extract x and y coordinates\n",
    "        x_coords = frame_data[0:50:2] \n",
    "        y_coords = frame_data[1:50:2]\n",
    "        emotion_vector = tuple(frame_data[-7:])\n",
    "        \n",
    "\n",
    "        # Get emotion percentages and labels\n",
    "        emotion_percentages = [f\"{int(e * 100)}% {label}\" for e, label in zip(emotion_vector, emotion_labels) if e > 0]\n",
    "\n",
    "\n",
    "        # Plot keypoints on the canvas\n",
    "        for i, (x, y) in enumerate(zip(x_coords, y_coords)):\n",
    "            x_val = x.item() if torch.is_tensor(x) else x\n",
    "            y_val = y.item() if torch.is_tensor(y) else y\n",
    "            cv2.circle(canvas_copy, (int(x_val), int(y_val)), 3, (0, 0, 255), -1)  \n",
    "            cv2.putText(canvas_copy, keypointsMapping[i], (int(x_val), int(y_val)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        # Draw connections (limbs) on the canvas\n",
    "        for limb in limb_connections:\n",
    "            start_point = (int(x_coords[keypointsMapping.index(limb[0])]), int(y_coords[keypointsMapping.index(limb[0])]))\n",
    "            end_point = (int(x_coords[keypointsMapping.index(limb[1])]), int(y_coords[keypointsMapping.index(limb[1])]))\n",
    "\n",
    "            if start_point == (0,0) or end_point == (0,0):\n",
    "                continue\n",
    "            cv2.line(canvas_copy, start_point, end_point, (0, 255, 0), 2)  \n",
    "        \n",
    "        # Display the emotion percentages and labels on the top right of the frame\n",
    "        y0, dy = 30, 15  # Starting y position and line gap\n",
    "        for i, line in enumerate(emotion_percentages):\n",
    "            y = y0 + i * dy\n",
    "            cv2.putText(canvas_copy, line, (canvas_size[1] - 120, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        # Display the canvas with keypoints and connections\n",
    "        cv2.imshow(\"Keypoints Visualization\", canvas_copy)\n",
    "\n",
    "        # If saving, write the frame to the video\n",
    "        if save:\n",
    "            out.write(canvas_copy)\n",
    "\n",
    "        # Wait for 100ms and check for \"esc\" key press to exit\n",
    "        key = cv2.waitKey(100)\n",
    "        if key == 27:  \n",
    "            break\n",
    "\n",
    "    # Release the video writer, if used\n",
    "    if save:\n",
    "        out.release()\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1326/1326 [00:00<00:00, 2044.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create 1D array of 50 numbers (x,y,x,y --> 25 keypoints) for each frame\n",
    "kp_frames = []\n",
    "n_parts = 25\n",
    "\n",
    "for i in tqdm(range(0, len(normalised_x))):\n",
    "    video_x = normalised_x[i]\n",
    "    video_y = normalised_y[i]\n",
    "    kp_frame= []\n",
    "    for j in range(0,len(video_x), n_parts):\n",
    "        frame_data = [coord for pair in zip(video_x[j:j+n_parts], video_y[j:j+n_parts]) for coord in pair]\n",
    "        kp_frame.append(frame_data)\n",
    "    kp_frames.append(kp_frame)\n",
    "\n",
    "len(kp_frames[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " [1, 0, 0, 0, 0, 0, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotion_labels_to_vectors(emotion_labels):\n",
    "    \"\"\"\n",
    "    Convert a list of emotion labels to a list of continuous emotion vectors.\n",
    "\n",
    "    Parameters:\n",
    "    - emotion_labels (list of str): A list of emotion labels.\n",
    "    \n",
    "    Returns:\n",
    "    - list of np.array: A list of continuous emotion vectors.\n",
    "    \"\"\"\n",
    "    # Define a mapping from emotion labels to emotion vectors\n",
    "    label_to_vector = {\n",
    "        'A': [1, 0, 0, 0, 0, 0, 0],   # Anger\n",
    "        'D': [0, 1, 0, 0, 0, 0, 0],   # Disgust\n",
    "        'F': [0, 0, 1, 0, 0, 0, 0],   # Fear\n",
    "        'H': [0, 0, 0, 1, 0, 0, 0],   # Happiness\n",
    "        'N': [0, 0, 0, 0, 1, 0, 0],   # Neutral\n",
    "        'SA': [0, 0, 0, 0, 0, 1, 0],  # Sad\n",
    "        'SU': [0, 0, 0, 0, 0, 0, 1]   # Surprise\n",
    "    }\n",
    "    \n",
    "    # Convert the labels to vectors using the mapping\n",
    "    emotion_vectors = [label_to_vector[label] for label in emotion_labels]\n",
    "    \n",
    "    return emotion_vectors\n",
    "\n",
    "# Convert labels to vectors\n",
    "emotion_vectors = emotion_labels_to_vectors(emotions_labels)\n",
    "emotion_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kp_frames[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1326/1326 [00:00<00:00, 29566.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_frames_with_emotion = []\n",
    "# kp_frames is normalised\n",
    "\n",
    "for i in tqdm(range(len(emotion_vectors))):\n",
    "    # Use list concatenation instead of extend() to avoid in-place modification and None\n",
    "    for frame in kp_frames[i]:\n",
    "        frame.extend(emotion_vectors[i])\n",
    "    kp_frames_with_emotion.append(kp_frames[i])\n",
    "    \n",
    "\n",
    "len(kp_frames_with_emotion[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets !FIX ALL VALIDATION BATCHES ARE ANGRY\n",
    "n = int(0.9*len(kp_frames_with_emotion)) # first 90% will be train, rest val\n",
    "train_data = kp_frames_with_emotion[:n]\n",
    "val_data = kp_frames_with_emotion[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([8, 10, 57])\n",
      "tensor([[[ 2.1034e-01, -4.6205e-01,  1.6415e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.1540e-01, -4.6203e-01,  1.6916e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.2557e-01, -4.6211e-01,  1.6426e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.5114e-01, -4.5628e-01,  1.6420e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.5130e-01, -4.5617e-01,  1.6415e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.4114e-01, -4.5016e-01,  1.6908e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.6886e-02, -3.8021e-01,  9.7409e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 8.7196e-02, -3.9179e-01,  1.0269e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 9.7363e-02, -3.9196e-01,  1.0787e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 1.3339e-01, -4.0356e-01,  1.3340e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2819e-01, -4.0922e-01,  1.3320e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.1783e-01, -4.0936e-01,  1.2315e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.5394e-02, -4.8531e-01, -5.1193e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.0434e-02, -4.6800e-01, -4.5989e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 3.0923e-02, -4.7381e-01, -3.0926e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.6185e-02, -5.0286e-01, -3.5801e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 7.1741e-02, -5.2046e-01, -2.0300e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0243e-01, -5.2045e-01,  1.4895e-04,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.1395e-03, -4.3287e-01,  1.0091e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2061e-03, -4.3290e-01,  1.0109e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2271e-03, -4.3286e-01,  1.0137e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 5.2622e-03, -4.3283e-01,  1.0165e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2446e-03, -4.3295e-01,  1.0186e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2867e-03, -4.3291e-01,  1.0186e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.6224e-02, -3.6247e-01,  2.0427e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 4.6063e-02, -3.5686e-01,  2.0434e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 4.6003e-02, -3.5679e-01,  1.5517e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.5725e-02, -3.6265e-01,  1.5559e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.0493e-02, -3.6259e-01,  1.5538e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0316e-02, -3.5692e-01,  2.0567e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.0133e-03, -3.9784e-01,  4.1142e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-5.2341e-03, -4.0344e-01,  3.5973e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-2.0346e-02, -4.0367e-01,  3.0916e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-5.6384e-02, -4.1539e-01,  2.5852e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-5.6373e-02, -4.1535e-01,  3.0670e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-5.1358e-02, -4.1549e-01,  3.0779e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "targets:\n",
      "torch.Size([8, 10, 57])\n",
      "tensor([[[ 2.1540e-01, -4.6203e-01,  1.6916e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.2557e-01, -4.6211e-01,  1.6426e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.4090e-01, -4.6203e-01,  1.6912e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.5130e-01, -4.5617e-01,  1.6415e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.4114e-01, -4.5016e-01,  1.6908e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.3606e-01, -4.3857e-01,  1.6420e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 8.7196e-02, -3.9179e-01,  1.0269e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 9.7363e-02, -3.9196e-01,  1.0787e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0778e-01, -3.9764e-01,  1.1796e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 1.2819e-01, -4.0922e-01,  1.3320e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.1783e-01, -4.0936e-01,  1.2315e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0271e-01, -4.0365e-01,  1.1791e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.0434e-02, -4.6800e-01, -4.5989e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 3.0923e-02, -4.7381e-01, -3.0926e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 4.6143e-02, -4.7375e-01, -2.5757e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 7.1741e-02, -5.2046e-01, -2.0300e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0243e-01, -5.2045e-01,  1.4895e-04,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2816e-01, -5.0872e-01,  1.5520e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.2061e-03, -4.3290e-01,  1.0109e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2271e-03, -4.3286e-01,  1.0137e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2271e-03, -4.3289e-01,  1.0172e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 5.2446e-03, -4.3295e-01,  1.0186e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.2867e-03, -4.3291e-01,  1.0186e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 5.3042e-03, -4.3285e-01,  1.0116e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.6063e-02, -3.5686e-01,  2.0434e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 4.6003e-02, -3.5679e-01,  1.5517e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 4.1146e-02, -3.5672e-01,  1.5531e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.0493e-02, -3.6259e-01,  1.5538e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.0316e-02, -3.5692e-01,  2.0567e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-4.9818e-03, -3.5696e-01,  2.0416e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-5.2341e-03, -4.0344e-01,  3.5973e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-2.0346e-02, -4.0367e-01,  3.0916e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-2.5659e-02, -4.0959e-01,  3.0741e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-5.6373e-02, -4.1535e-01,  3.0670e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-5.1358e-02, -4.1549e-01,  3.0779e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-5.1078e-02, -4.1550e-01,  3.0891e-02,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)\n",
    "def get_batch(split, block_size, batch_size, device=device):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    \n",
    "    # Choose random videos\n",
    "    ix = torch.randint(len(data), (batch_size,))\n",
    "\n",
    "    # For each chosen video, select a random starting point\n",
    "    start_frames = [torch.randint(len(data[i]) - block_size, (1,)).item() for i in ix]\n",
    "\n",
    "    # Extract subsequences from each chosen video and convert to tensors\n",
    "    x = torch.stack([torch.tensor(data[i][start:start+block_size], dtype=torch.float32) for i, start in zip(ix, start_frames)])\n",
    "    y = torch.stack([torch.tensor(data[i][start+1:start+block_size+1], dtype=torch.float32) for i, start in zip(ix, start_frames)])\n",
    "\n",
    "    # Compute the mask to mask out -inf values\n",
    "    mask = (x != float('-inf')).all(dim=-1).float()  # assuming -inf is present in any part of the data point\n",
    "\n",
    "    # Move tensors to the designated device\n",
    "    x, y, mask = x.to(device), y.to(device), mask.to(device)\n",
    "    \n",
    "    return x, y, mask\n",
    "block_size = 10  # example block size\n",
    "batch_size = 8   # example batch size\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # example device\n",
    "\n",
    "# Get a batch from training data (assuming data is a nested list)\n",
    "xb, yb, mask = get_batch('train',  block_size, batch_size, device)\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_list = ['Anger', 'Disgust', 'Fear', 'Happiness', 'Neutral', 'Sad', 'Surprise']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions are consistent between x and y.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def validate_emotion_consistency(x, y):\n",
    "    \"\"\"\n",
    "    Validate that the emotion code (last 7 elements of each frame) is consistent\n",
    "    between corresponding frames in x and y.\n",
    "\n",
    "    Parameters:\n",
    "    - x (Tensor): Input sequences (batch_size, sequence_length, frame_length)\n",
    "    - y (Tensor): Target sequences (batch_size, sequence_length, frame_length)\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if emotions are consistent, False otherwise\n",
    "    \"\"\"\n",
    "    # Extract the emotion encodings from x and y\n",
    "    emotion_x = x[:, :, -7:]\n",
    "    emotion_y = y[:, :, -7:]\n",
    "\n",
    "    # Check if the emotion encodings are equal in x and y\n",
    "    emotion_equal = torch.all(emotion_x == emotion_y, dim=-1)\n",
    "    \n",
    "    # Check equality across sequence length (assuming dim 1 is sequence_length)\n",
    "    emotion_equal = torch.all(emotion_equal, dim=-1)\n",
    "\n",
    "    # Check if all batches have consistent emotions\n",
    "    all_equal = torch.all(emotion_equal)\n",
    "\n",
    "    return all_equal.item()\n",
    "\n",
    "\n",
    "# Example tensors (ensure your actual tensors match these dimensions)\n",
    "\n",
    "\n",
    "# Validate emotion consistency\n",
    "is_consistent = validate_emotion_consistency(xb, yb)\n",
    "\n",
    "# Output result\n",
    "if is_consistent:\n",
    "    print(\"Emotions are consistent between x and y.\")\n",
    "else:\n",
    "    print(\"Emotions are NOT consistent between x and y.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10, 57])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 10, 57])\n",
      "tensor([[[-2.4652e-01,  2.5268e-01,  4.8962e-01,  ...,  4.6004e-02,\n",
      "           3.5762e-01, -5.1999e-01],\n",
      "         [ 1.4183e-01, -8.0512e-02,  5.2776e-01,  ...,  1.7338e-01,\n",
      "           3.6658e-01,  4.8682e-02],\n",
      "         [ 3.2835e-04,  1.0642e-01,  3.8007e-01,  ...,  1.2639e-01,\n",
      "           3.2196e-01, -9.8446e-02],\n",
      "         ...,\n",
      "         [-3.7989e-01,  5.3269e-01,  3.4559e-01,  ...,  1.8851e-01,\n",
      "           2.2508e-02, -2.9736e-01],\n",
      "         [-2.3859e-01,  3.2742e-01,  9.6280e-02,  ...,  3.3373e-01,\n",
      "          -2.7553e-01, -1.6872e-01],\n",
      "         [-4.7830e-01,  6.0562e-01,  1.3307e-01,  ...,  9.5172e-02,\n",
      "           4.0212e-02, -1.2336e-01]],\n",
      "\n",
      "        [[ 8.1328e-02,  1.1428e-01,  4.6703e-01,  ...,  6.9837e-02,\n",
      "           1.3358e-01, -6.5106e-02],\n",
      "         [ 1.2646e-01,  2.8588e-01,  3.6268e-01,  ...,  1.0876e-01,\n",
      "           4.2022e-02, -6.5093e-01],\n",
      "         [-3.1011e-01,  4.5299e-01,  5.2181e-01,  ...,  2.9340e-01,\n",
      "           2.6440e-01, -1.8094e-01],\n",
      "         ...,\n",
      "         [-1.3284e-02,  7.4856e-01,  2.5802e-01,  ...,  1.3659e-01,\n",
      "           4.1181e-01, -4.6367e-01],\n",
      "         [-2.5593e-01,  3.4353e-01,  5.5487e-01,  ...,  1.4501e-01,\n",
      "          -4.6299e-02, -1.1698e-01],\n",
      "         [-4.5390e-01,  7.9790e-01,  2.4138e-01,  ...,  2.3251e-02,\n",
      "          -2.0848e-02, -2.5879e-01]],\n",
      "\n",
      "        [[ 4.1282e-01,  3.4517e-01,  4.1748e-01,  ...,  2.5012e-01,\n",
      "           2.2441e-01,  9.3121e-02],\n",
      "         [-1.9791e-01,  3.8233e-01,  6.7751e-01,  ...,  4.4811e-02,\n",
      "           3.5135e-01, -5.2731e-01],\n",
      "         [-2.5129e-02,  5.0591e-01,  5.4793e-01,  ..., -4.3144e-02,\n",
      "           1.8599e-01, -2.0883e-01],\n",
      "         ...,\n",
      "         [-1.6077e-01,  7.7806e-01, -1.1408e-02,  ...,  4.4155e-01,\n",
      "           2.0983e-01, -2.4595e-01],\n",
      "         [-2.8631e-01,  5.0158e-01, -7.6502e-02,  ...,  3.0166e-01,\n",
      "           1.1186e-01, -3.4556e-01],\n",
      "         [-7.9260e-02,  4.6304e-01,  1.2733e-01,  ...,  3.3925e-01,\n",
      "           4.3132e-01, -3.6019e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.9675e-01,  3.5717e-01,  3.1841e-01,  ...,  3.9931e-02,\n",
      "           7.5260e-02,  1.0351e-01],\n",
      "         [-1.0567e-01,  1.5584e-01,  1.7673e-01,  ...,  6.7117e-02,\n",
      "           2.1060e-01, -1.5285e-01],\n",
      "         [-1.2373e-02,  2.8591e-01,  5.5189e-01,  ..., -5.4407e-02,\n",
      "           2.7998e-01,  3.3669e-02],\n",
      "         ...,\n",
      "         [-7.9930e-03,  4.6692e-01,  1.9649e-01,  ...,  3.7703e-01,\n",
      "           3.0257e-01, -2.7136e-01],\n",
      "         [-2.2243e-01,  5.7125e-01,  3.2683e-01,  ...,  5.6210e-01,\n",
      "           7.2413e-03, -3.2114e-01],\n",
      "         [-9.7251e-02,  2.2488e-01,  2.6307e-01,  ...,  2.2605e-01,\n",
      "           2.3446e-01, -2.9125e-01]],\n",
      "\n",
      "        [[-5.2715e-01,  5.9274e-02,  4.0559e-01,  ..., -1.6058e-02,\n",
      "           1.4288e-01, -3.1399e-01],\n",
      "         [-1.7709e-01, -7.2182e-02,  4.7154e-01,  ...,  3.2429e-01,\n",
      "           1.7324e-01, -6.8345e-02],\n",
      "         [-6.6083e-02,  2.1868e-01,  3.3641e-01,  ...,  2.4761e-01,\n",
      "          -7.9557e-02, -1.2569e-01],\n",
      "         ...,\n",
      "         [-5.2441e-01,  4.8209e-01,  2.5659e-01,  ...,  4.5638e-01,\n",
      "           2.8188e-01, -4.9023e-01],\n",
      "         [-3.6549e-01,  6.1710e-01,  3.7558e-01,  ...,  5.0171e-01,\n",
      "          -6.5110e-02, -1.7973e-01],\n",
      "         [-1.9349e-01,  7.2452e-01,  2.5170e-01,  ...,  1.3113e-01,\n",
      "           3.9785e-01, -4.9849e-01]],\n",
      "\n",
      "        [[-2.2024e-01,  4.8025e-01,  2.3360e-01,  ...,  8.2953e-02,\n",
      "          -2.3953e-01, -3.2903e-01],\n",
      "         [-1.0645e-01, -5.1087e-02,  5.0807e-01,  ..., -3.0469e-02,\n",
      "           9.7953e-02,  2.2311e-02],\n",
      "         [-2.0537e-01,  4.0084e-01,  5.4749e-01,  ...,  1.2593e-01,\n",
      "          -5.1691e-02, -4.7299e-01],\n",
      "         ...,\n",
      "         [-3.5316e-01,  5.6520e-01,  2.2728e-01,  ...,  4.7390e-01,\n",
      "           2.5907e-01, -5.1148e-01],\n",
      "         [-4.3294e-01,  4.8563e-01,  6.5810e-02,  ...,  3.2116e-01,\n",
      "           1.2522e-01, -1.8110e-01],\n",
      "         [-3.9012e-01,  2.6675e-01,  1.9340e-01,  ...,  3.3200e-01,\n",
      "           1.7942e-01, -1.6650e-01]]], device='cuda:0',\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "loss: 0.2386867105960846\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# let's start with a very simple model\n",
    "\n",
    "def positional_encoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Returns the positional encoding for a given sequence length and model size.\n",
    "\n",
    "    Parameters:\n",
    "    - seq_len (int): Length of the sequence.\n",
    "    - d_model (int): Size of the model embedding.\n",
    "\n",
    "    Returns:\n",
    "    - A tensor of shape (seq_len, d_model) containing the positional encoding.\n",
    "    \"\"\"\n",
    "    \n",
    "    position = torch.arange(seq_len).unsqueeze(1).float() # [seq_len, 1]\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                         (-math.log(10000.0) / d_model))  # [d_model/2]\n",
    "    pos_enc = torch.zeros((seq_len, d_model))\n",
    "\n",
    "    pos_enc[:, 0::2] = torch.sin(position * div_term) # apply sin to even indices in the array; 2i\n",
    "    pos_enc[:, 1::2] = torch.cos(position * div_term) # apply cos to odd indices in the array; 2i+1\n",
    "\n",
    "    return pos_enc\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\"one head of self attention\"\"\"\n",
    "    \n",
    "    def __init__(self,head_size,n_emb,dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_emb, head_size, bias=False, device=device)\n",
    "        self.query = nn.Linear(n_emb, head_size, bias=False, device=device)\n",
    "        self.value = nn.Linear(n_emb, head_size, bias=False, device=device)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.n_emb = n_emb\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape # batch size, time, context\n",
    "        # key, query, value\n",
    "        k = self.key(x) # B,T,C\n",
    "        q = self.query(x) # B,T,C\n",
    "        v= self.value(x) # B,T,C\n",
    "        \n",
    "        # compute attention scores (\"affinities\")\n",
    "         # Scaled dot-product attention - same as below\n",
    "        # attention = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys]) / math.sqrt(self.embed_size)\n",
    "\n",
    "        wei = q @ k.transpose(-1,-2) # B,T,T\n",
    "        wei /= math.sqrt(self.n_emb) # scale by sqrt of embedding dimension\n",
    "        self.tril = self.tril.to(device)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # mask out upper triangular part so don't attend to future\n",
    "        wei = F.softmax(wei, dim=-1) # B,T,T\n",
    "        wei = self.dropout(wei)\n",
    "        # apply attention to values - weighted aggregation\n",
    "        out = wei @ v # (B,T,T) @ (B,T,C) --> B,T,C\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_heads,head_size,n_emb,dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size,n_emb) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_emb, n_emb, bias=False, device=device) # (B,T,C) - projection back into residual pathway\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x is (B,T,C)\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B,T,C*num_heads)\n",
    "        out = self.dropout(self.proj(out)) # (B,T,C) - projection back into residual pathway\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"A simple lineear layer followed by a ReLU - allows all tokens to think on data individually\"\"\"\n",
    "    \n",
    "    def __init__(self,n_emb,dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_emb, 4 * n_emb , device=device), # 4 * because recommended in paper residual pathway - growing residual pathway\n",
    "            nn.ReLU(),\n",
    "            nn.Linear( 4* n_emb, n_emb , device=device), # required otherwise output will collapse  - projection back into residual pathway\n",
    "            nn.Dropout(dropout)\n",
    "          \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"Transformer Block: communication followed by computation - basically self attention heads and feedforward\"\"\"\n",
    "\n",
    "    def __init__(self, n_emb, n_heads):\n",
    "        \n",
    "        super().__init__()\n",
    "        head_size = n_emb//n_heads\n",
    "        self.sa = MultiHeadAttention(num_heads=n_heads, head_size=head_size, n_emb=n_emb)\n",
    "        self.ffwd = FeedForward(n_emb=n_emb)\n",
    "        self.ln1 =  nn.InstanceNorm1d(n_emb , device=device)\n",
    "        self.ln2 =  nn.InstanceNorm1d(n_emb, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x + due to residual connection\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class MotionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=256, n_layers=8):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=False, device=device)  #input to hidden dim\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim, bias=False,device=device)  #reshape hidden to output dim\n",
    "        self.positional_encoding = positional_encoding(seq_len=block_size, d_model=hidden_dim).to(device)\n",
    "        layers = [Block(n_emb=hidden_dim, n_heads=4) for _ in range(n_layers)]\n",
    "        layers.append(nn.InstanceNorm1d(hidden_dim, device=device))\n",
    "        self.blocks = nn.Sequential(*layers)\n",
    "\n",
    "        self.lm_head = nn.Linear(hidden_dim, hidden_dim, bias=False, device=device)\n",
    "       \n",
    "    \n",
    "        \n",
    "    def forward(self, inputs, targets=None ,mask=None):\n",
    "        B,T,C = inputs.shape # batch size, time, context\n",
    "        \n",
    "        # fc1 transforms input into hidden dimension\n",
    "        x = self.fc1(inputs) # B,T,hidden dimension\n",
    "        # Add positional encoding\n",
    "       \n",
    "        x += positional_encoding(seq_len=T, d_model=self.hidden_dim).to(device) # positional_encoding = T,hidden dimension , added = B,T,hidden dimension\n",
    "        \n",
    "        x = self.blocks(x) # B,T,hidden dimension\n",
    "        x = self.lm_head(x) # B,T,hidden dimension\n",
    "        \n",
    "        # fc2 transforms hidden dimension into output dimension\n",
    "        logits = self.fc2(x)\n",
    "        \n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        \n",
    "        else:\n",
    "            B,T,C = inputs.shape # batch size, time, context\n",
    "            loss = F.mse_loss(logits, targets) # mse picked cause continous data\n",
    "            # adding mask to ignore 0,0 occlusions (-inf)\n",
    "            # if mask is None:\n",
    "            #     mask = (inputs != float('-inf')).all(dim=-1).float() \n",
    "              \n",
    "            # loss = F.mse_loss(logits * mask.unsqueeze(-1), targets * mask.unsqueeze(-1), reduction='sum') / mask.sum()\n",
    "\n",
    "        \n",
    "        return logits,loss\n",
    "    \n",
    "    def generate(self,inputs,max_new_tokens):\n",
    "        # inputs is (B,T) array of indices in current context\n",
    "        # get current prediction\n",
    "    \n",
    "        generated_sequence = inputs\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            cond_sequence = generated_sequence[:, -block_size:] # get the last block_size tokens from the generated sequence so positional doesn't run out\n",
    "            # don't actually need to do this cause positional is sinusoidal but just in case since model trained with blocksize\n",
    "            logits, _ = self(cond_sequence)\n",
    "            next_values = logits[:, -1, :]  # Get the values from the last timestep\n",
    "            \n",
    "            # Append the predicted values to the sequence\n",
    "            generated_sequence = torch.cat([generated_sequence, next_values.unsqueeze(1)], dim=1)\n",
    "        \n",
    "        return generated_sequence\n",
    "\n",
    "# output dim should be the same size as target dim\n",
    "m = MotionModel(input_dim=57, output_dim=57)\n",
    "out,loss = m(xb, yb)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "# loss interpreted on scale of data\n",
    "print(f\"loss: {loss}\")\n",
    "\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/50000 [01:48<224:08:05, 16.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.001589 val loss: 0.001799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5005/50000 [06:21<85:53:15,  6.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000650 val loss: 0.000665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10005/50000 [10:58<71:07:34,  6.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000583 val loss: 0.000613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15005/50000 [15:30<67:47:45,  6.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000548 val loss: 0.000548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20005/50000 [19:58<48:50:20,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000523 val loss: 0.000559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25004/50000 [24:24<49:22:39,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000531 val loss: 0.000587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30004/50000 [28:57<34:43:52,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000442 val loss: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35005/50000 [33:22<23:01:57,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000454 val loss: 0.000494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40004/50000 [37:53<19:43:58,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000432 val loss: 0.000499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45005/50000 [42:33<10:12:34,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.000407 val loss: 0.000489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [45:13<00:00, 18.42it/s]   \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    eval_iters = 5000\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            xb, yb, mask = get_batch(split,  block_size, batch_size, device)\n",
    "            logits, loss = m(xb, yb)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for steps in tqdm(range(50000)):\n",
    "    # get sample batch of data\n",
    "    xb,yb,mask = get_batch('train',  block_size, batch_size, device)\n",
    "    # evaluate loss\n",
    "    logits, loss = m(xb,yb, mask)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if steps % 5000 == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"train loss: {losses['train']:.6f} val loss: {losses['val']:.6f}\")\n",
    "        \n",
    "         # Store the losses for plotting\n",
    "        train_losses.append(losses['train'])\n",
    "        val_losses.append(losses['val'])\n",
    "        \n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Steps (in thousands)')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "# After the training loop, plot the losses\n",
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"proto4_checkpoint.pth\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Try to delete the file (be cautious with this step)\n",
    "try:\n",
    "    os.remove(checkpoint_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"{checkpoint_path} not found, proceeding...\")\n",
    "except PermissionError:\n",
    "    print(f\"Cannot delete {checkpoint_path}. Check permissions.\")\n",
    "\n",
    "# Test write permissions\n",
    "try:\n",
    "    with open(checkpoint_path, 'w') as f:\n",
    "        f.write(\"test\")\n",
    "except PermissionError:\n",
    "    print(f\"Cannot write to {checkpoint_path}. Check permissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 310, 57])\n"
     ]
    }
   ],
   "source": [
    "# generate new sequence\n",
    "xb,yb,mask = get_batch('test', block_size, batch_size, device)\n",
    "\n",
    "generated = m.generate(xb, 300)\n",
    "print(generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\\notebooks\\prototypes\\inter-prototype-4.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# visualise and save\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m unnorm_out:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     visualise_skeleton(batch, max_x, max_y, max_frames\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,save \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,save_path\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,prefix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39madam_10000steps_proto4\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\\notebooks\\prototypes\\inter-prototype-4.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m     out\u001b[39m.\u001b[39mwrite(canvas_copy)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39m# Wait for 100ms and check for \"esc\" key press to exit\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m key \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m100\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m27\u001b[39m:  \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/notebooks/prototypes/inter-prototype-4.ipynb#X33sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def unnormalise_list(data_tensor, max_x, min_x, max_y, min_y):\n",
    "    all_frames = []\n",
    "    # Loop through each batch\n",
    "    for batch_idx in range(data_tensor.size(0)):\n",
    "        batch_frames = []\n",
    "        # Loop through each frame in the batch\n",
    "        for frame_idx in range(data_tensor.size(1)):\n",
    "            frame_data = data_tensor[batch_idx, frame_idx, :]\n",
    "            unnormalized_data = []\n",
    "            # Loop through the coordinate pairs and unnormalize\n",
    "            for i in range(0, 50, 2):  \n",
    "                x = frame_data[i]\n",
    "                y = frame_data[i+1]\n",
    "                unnormalized_x = (x+1)/2 * (max_x-min_x) + min_x\n",
    "                unnormalized_y = (y+1)/2 * (max_y-min_y) + min_y\n",
    "                unnormalized_data.extend([unnormalized_x.item(), unnormalized_y.item()])\n",
    "            # Append the emotion encoding without unnormalizing\n",
    "            unnormalized_data.extend(frame_data[-7:].tolist())\n",
    "            batch_frames.append(unnormalized_data)\n",
    "        all_frames.append(batch_frames)\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "\n",
    "unnorm_out = unnormalise_list(generated, max_x, min_x, max_y, min_y)\n",
    "\n",
    "# visualise and save\n",
    "for batch in unnorm_out:\n",
    "    visualise_skeleton(batch, max_x, max_y, max_frames=300,save = True,save_path=None,prefix='adam_10000steps_proto4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # continuous GPT\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn import functional as F\n",
    "# import math\n",
    "\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "# # this is set to eval mode because we don't want to train the model, we just want to estimate the loss, for this model the modes won't be different\n",
    "# # but for other models, the modes will be different depending on what layers are present\n",
    "# # torch.no_grad() - we don't want to calculate gradients because we don't want to train the model, we will not call backward, better memory management\n",
    "# @torch.no_grad()\n",
    "# def estimate_loss():\n",
    "#     out = {}\n",
    "#     model.eval()\n",
    "#     eval_iters = 200\n",
    "#     for split in ['train', 'val']:\n",
    "#         losses = torch.zeros(eval_iters)\n",
    "#         for k in range(eval_iters):\n",
    "#             xb, yb = get_batch(split)\n",
    "#             logits, loss = model(xb, yb)\n",
    "#             losses[k] = loss.item()\n",
    "#         out[split] = losses.mean()\n",
    "#     model.train()\n",
    "#     return out\n",
    "\n",
    "# def positional_encoding(seq_len, d_model):\n",
    "#     \"\"\"\n",
    "#     Returns the positional encoding for a given sequence length and model size.\n",
    "\n",
    "#     Parameters:\n",
    "#     - seq_len (int): Length of the sequence.\n",
    "#     - d_model (int): Size of the model embedding.\n",
    "\n",
    "#     Returns:\n",
    "#     - A tensor of shape (seq_len, d_model) containing the positional encoding.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     position = torch.arange(seq_len).unsqueeze(1).float() # [seq_len, 1]\n",
    "#     div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "#                          (-math.log(10000.0) / d_model))  # [d_model/2]\n",
    "#     pos_enc = torch.zeros((seq_len, d_model))\n",
    "\n",
    "#     pos_enc[:, 0::2] = torch.sin(position * div_term) # apply sin to even indices in the array; 2i\n",
    "#     pos_enc[:, 1::2] = torch.cos(position * div_term) # apply cos to odd indices in the array; 2i+1\n",
    "\n",
    "#     return pos_enc\n",
    "\n",
    "\n",
    "\n",
    "# class MotionModel(nn.Module):\n",
    "\n",
    "#     def __init__(self, input_dim, hidden_dim, num_heads, num_layers):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Initial transformation layer\n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "#         # Transformer layers\n",
    "#         encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads)\n",
    "#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "#         # Positional encoding\n",
    "#         self.positional_encoding = positional_encoding(seq_len=block_size, d_model=hidden_dim).to(device)\n",
    "\n",
    "#         # Output layer\n",
    "#         self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "#     def forward(self, pose_sequence,targets=None):\n",
    "#         # Feature transformation\n",
    "#         x = self.fc1(pose_sequence)\n",
    "\n",
    "#         # Add positional encoding\n",
    "#         seq_len = x.shape[1]\n",
    "#         x += self.positional_encoding[:seq_len, :]\n",
    "\n",
    "\n",
    "#         # Transformer layers\n",
    "#         x = self.transformer(x)\n",
    "\n",
    "#         # Predicting the next pose\n",
    "#         logits = self.fc2(x)\n",
    "        \n",
    "        \n",
    "#         if targets is None:\n",
    "#             loss = None\n",
    "#         else:\n",
    "#             B, T, C = logits.shape\n",
    "#             # pytorch wants (B*T,C) so we have to transpose because it wants C in the 2nd dimension\n",
    "#             logits = logits.view(B*T, C)\n",
    "#             # look at prediction\n",
    "#             targets = targets.view(B*T, -1)\n",
    "\n",
    "#             # evaluate loss\n",
    "#             # negative log likelihood loss a.k. cross entropy loss\n",
    "#             # we have the identity of the next character so how well are we predicting the next character based on the logits\n",
    "#             # ideally the correct logits should be 1 and the rest should be 0, but in reality this is not the case\n",
    "            \n",
    "#             loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "#         return logits,loss\n",
    "\n",
    "#     def training_step(self, pose_sequence, next_pose):\n",
    "#         predicted_pose = self(pose_sequence)\n",
    "#         loss = nn.MSELoss()(predicted_pose, next_pose)\n",
    "#         return loss\n",
    "    \n",
    "#     def generate(self, initial_pose_sequence, max_new_poses):\n",
    "#         \"\"\"\n",
    "#         Generate a sequence of poses.\n",
    "\n",
    "#         Parameters:\n",
    "#         - initial_pose_sequence: Starting sequence of poses.\n",
    "#         - max_new_poses: Maximum number of new poses to generate.\n",
    "\n",
    "#         Returns:\n",
    "#         - Generated sequence of poses.\n",
    "#         \"\"\"\n",
    "\n",
    "#         generated_sequence = initial_pose_sequence\n",
    "\n",
    "#         for _ in range(max_new_poses):\n",
    "#             # Get the predicted next pose\n",
    "#             logits, _ = self(generated_sequence)\n",
    "#             next_pose = logits\n",
    "\n",
    "\n",
    "#             # Append the predicted pose to the sequence\n",
    "#             generated_sequence = torch.cat([initial_pose_sequence,next_pose],dim=1)  # Add sequence dimension\n",
    "\n",
    "\n",
    "#         return generated_sequence\n",
    "\n",
    "\n",
    "\n",
    "# model = MotionModel(input_dim=50, hidden_dim=128, num_heads=4, num_layers=4)\n",
    "# m = model.to(device)\n",
    "# logits, loss = m(xb, yb)\n",
    "# print(logits.shape)\n",
    "# print(loss)\n",
    "# output= m.generate(initial_pose_sequence=xb[0], max_new_poses=100)[0].tolist()\n",
    "# print(np.shape(output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess the MEED dataset for transformer\n",
    "# # 1D array of 50 (25 keypoints x,y ) = 1 frame = 1 token\n",
    "# # block size of 10 so input is 10x50 dims\n",
    "\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# # Example: load your keypoints from a file, preprocess, and convert them into PyTorch tensors\n",
    "# # keypoints = ...\n",
    "# # For the sake of this example, let's assume keypoints is a torch.Tensor of shape [num_samples, sequence_len, 50]\n",
    "\n",
    "# # Create data loaders\n",
    "# batch_size = 32\n",
    "# train_loader = DataLoader(xb, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(yb, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive_dance_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
