{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\n",
      "\n",
      "    Batch size set to: 1\n",
      "    Block size set to: 16\n",
      "    Dropout rate set to: 0.2\n",
      "    Learning rate set to: 0.0001\n",
      "    Number of epochs set to: 100000\n",
      "    Frames to generate set to: 150\n",
      "    Training mode set to: False\n",
      "    Evaluation every set to: 1000\n",
      "    Checkpoint path set to: checkpoints/proto8_checkpoint_temp.pth\n",
      "    L1 regularization lambda set to: None\n",
      "    L2 regularization lambda set to: 0.0\n",
      "    Fine-tuning mode set to: False\n",
      "    Fine-tuning learning rate set to: 1e-05\n",
      "    Fine-tuning epochs set to: 100000\n",
      "    Penalty flag set to: False\n",
      "    Latent visualization every set to: 1000\n",
      "    Use MDN flag set to: True\n",
      "    Dataset set to: all\n",
      "    Patience: 10\n",
      "    \n",
      "Preparing data for all...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4102/4102 [00:03<00:00, 1084.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating interpolation...\n",
      "No errors found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4102it [00:01, 2354.05it/s]\n",
      "4102it [00:01, 2427.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 109/109 [00:05<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating interpolation...\n",
      "No errors found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "109it [00:00, 288.12it/s]\n",
      "109it [00:00, 280.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating keypoint frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4211/4211 [00:03<00:00, 1391.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating keypoint frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4211/4211 [00:03<00:00, 1080.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating length of dkp_frames\n",
      "Validating length of kp_frames\n",
      "Adding deltas to frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4211it [00:02, 1432.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating length of data after delta\n",
      "frame_dim: 100\n",
      "2023-11-15 18:57:42 [Poco]- Israel Forever - Forever Israel :red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart: Israel Forever - Forever Israel :red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:red_heart:ðŸ‡®ðŸ‡±:hundred_points:\n",
      "[{'label': 'joy', 'score': 0.6289936900138855}]\n",
      "Average scores: [0.0, 0.0, 0.0, 0.6289936900138855, 0.0, 0.0, 0.0]\n",
      "2023-11-15 18:57:43 [XretroBox420]- They should just send Jewish People back to their homelands in Europe. They'll be treated real nicely there!!!\n",
      "[{'label': 'anger', 'score': 0.8370621800422668}]\n",
      "Average scores: [0.8370621800422668, 0.0, 0.0, 0.31449684500694275, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (generate_batches_periodically):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\avika\\anaconda3\\envs\\interactive_dance_thesis\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\avika\\AppData\\Local\\Temp\\ipykernel_45352\\1679118185.py\", line 266, in generate_batches_periodically\n",
      "  File \"C:\\Users\\avika\\AppData\\Local\\Temp\\ipykernel_45352\\1679118185.py\", line 256, in generate_new_batch\n",
      "  File \"c:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\\model.py\", line 327, in generate\n",
      "    if USE_MDN:\n",
      "NameError: name 'USE_MDN' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-15 18:57:47 [Iblis]- :victory_hand:\n",
      "[{'label': 'neutral', 'score': 0.9853259325027466}]\n",
      "Average scores: [0.4185310900211334, 0.0, 0.0, 0.15724842250347137, 0.9853259325027466, 0.0, 0.0]\n",
      "2023-11-15 18:57:51 [Linda Hlatshwako]- dead hope...they should stay in lebanon\n",
      "[{'label': 'neutral', 'score': 0.9353736639022827}]\n",
      "Average scores: [0.2092655450105667, 0.0, 0.0, 0.07862421125173569, 1, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import keyboard\n",
    "import queue\n",
    "from model import *\n",
    "import pytchat\n",
    "from data import *\n",
    "\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"michellejieli/emotion_text_classifier\")\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"michellejieli/emotion_text_classifier\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"michellejieli/emotion_text_classifier\")\n",
    "\n",
    "# Define a function to set global variables\n",
    "def set_globals(args):\n",
    "    global PATIENCE, BATCH_SIZE,DATASET, BLOCK_SIZE, DROPOUT, LEARNING_RATE, EPOCHS, FRAMES_GENERATE, TRAIN, EVAL_EVERY, CHECKPOINT_PATH, L1_LAMBDA, L2_REG, FINETUNE, FINE_TUNING_LR, FINE_TUNING_EPOCHS, PENALTY, LATENT_VIS_EVERY, notes,USE_MDN\n",
    "    BATCH_SIZE = args.BATCH_SIZE\n",
    "    BLOCK_SIZE = args.BLOCK_SIZE\n",
    "    DROPOUT = args.DROPOUT\n",
    "    LEARNING_RATE = args.LEARNING_RATE\n",
    "    EPOCHS = args.EPOCHS\n",
    "    FRAMES_GENERATE = args.FRAMES_GENERATE\n",
    "    TRAIN = args.TRAIN\n",
    "    EVAL_EVERY = args.EVAL_EVERY\n",
    "    CHECKPOINT_PATH = args.CHECKPOINT_PATH\n",
    "    L1_LAMBDA = args.L1_LAMBDA\n",
    "    L2_REG = args.L2_REG\n",
    "    FINETUNE = args.FINETUNE\n",
    "    FINE_TUNING_LR = args.FINE_TUNING_LR\n",
    "    FINE_TUNING_EPOCHS = args.FINE_TUNING_EPOCHS\n",
    "    PENALTY = args.PENALTY\n",
    "    LATENT_VIS_EVERY = args.LATENT_VIS_EVERY\n",
    "    USE_MDN = args.USE_MDN\n",
    "    DATASET = args.DATASET\n",
    "    notes = args.notes\n",
    "    PATIENCE = args.PATIENCE\n",
    "    \n",
    "    # ---------------------------------\n",
    "    notes = f\"\"\"Proto8 - trying to adapt Pette et al 2019, addign latent visualisation and analysing latent space. Might be slow, maybe take this out when live.\n",
    "\n",
    "    \n",
    "    Added MDN layer to model.\n",
    "    \n",
    "    All data, added 10% noise to emotions so model is less stuck. With LeakyRelu\n",
    "    Loss = mse_loss(keypoints) + mse_loss(emotions) because before output emotions ( which feature was added to keypoint features) were not being matched to input emotions\n",
    "    No penalty.\n",
    "\n",
    "    Added dropout to keypoints, also changed input to emotion linear to x and not just emotion (emotion + keypoints)\n",
    "    Taking extra dropout for emotions and keypoints out, because want model to rely on both equally so what's the point\n",
    "\n",
    "    dropout keypoints and dropout emotion is currently equal but might change this.\n",
    "\n",
    "    Emotions and keypoints are multimodal and added separately, but features are added in block processing using +.\n",
    "\n",
    "\n",
    "    Got rid of both L1 and L2, increasing dropout because model acting weird, this is now delta + coord. \n",
    "    Delta is between next frame and current frame. So current frame is previous coord+previous delta. Last frame's delta is 0. \n",
    "    \n",
    "    {BATCH_SIZE} batch size, {BLOCK_SIZE} block size, {DROPOUT} dropout, {LEARNING_RATE} learning rate, {EPOCHS} epochs, {FRAMES_GENERATE} frames generated, {TRAIN} train, {EVAL_EVERY} eval every, {CHECKPOINT_PATH} checkpoint path, {L1_LAMBDA} L1 lambda, {L2_REG} L2 reg\"\"\"\n",
    "    # ---------------------------------\n",
    "    \n",
    "    # Print the values using f-string for formatting\n",
    "    print(f\"\"\"\n",
    "    Batch size set to: {BATCH_SIZE}\n",
    "    Block size set to: {BLOCK_SIZE}\n",
    "    Dropout rate set to: {DROPOUT}\n",
    "    Learning rate set to: {LEARNING_RATE}\n",
    "    Number of epochs set to: {EPOCHS}\n",
    "    Frames to generate set to: {FRAMES_GENERATE}\n",
    "    Training mode set to: {TRAIN}\n",
    "    Evaluation every set to: {EVAL_EVERY}\n",
    "    Checkpoint path set to: {CHECKPOINT_PATH}\n",
    "    L1 regularization lambda set to: {L1_LAMBDA}\n",
    "    L2 regularization lambda set to: {L2_REG}\n",
    "    Fine-tuning mode set to: {FINETUNE}\n",
    "    Fine-tuning learning rate set to: {FINE_TUNING_LR}\n",
    "    Fine-tuning epochs set to: {FINE_TUNING_EPOCHS}\n",
    "    Penalty flag set to: {PENALTY}\n",
    "    Latent visualization every set to: {LATENT_VIS_EVERY}\n",
    "    Use MDN flag set to: {USE_MDN}\n",
    "    Dataset set to: {DATASET}\n",
    "    Patience: {PATIENCE}\n",
    "    \"\"\")\n",
    "    \n",
    "\n",
    "# initialise model------------------------------------------------------------\n",
    "\n",
    "\n",
    "args = argparse.Namespace(\n",
    "        BATCH_SIZE=1,\n",
    "        BLOCK_SIZE=16,\n",
    "        DROPOUT=0.2,\n",
    "        LEARNING_RATE=0.0001,\n",
    "        EPOCHS=100000,\n",
    "        FRAMES_GENERATE=150,\n",
    "        TRAIN=False,\n",
    "        EVAL_EVERY=1000,\n",
    "        CHECKPOINT_PATH=\"checkpoints/proto8_checkpoint_temp.pth\",\n",
    "        L1_LAMBDA=None,\n",
    "        L2_REG=0.0,\n",
    "        FINETUNE=False,\n",
    "        FINE_TUNING_LR=1e-5,\n",
    "        FINE_TUNING_EPOCHS=100000,\n",
    "        PENALTY=False,\n",
    "        LATENT_VIS_EVERY=1000,\n",
    "        USE_MDN = True,\n",
    "        DATASET = \"all\",\n",
    "        PATIENCE = 10,\n",
    "        \n",
    "        # NOTES---------------------------------\n",
    "        notes = f\"\"\"Proto8 - trying to adapt Pette et al 2019, addign latent visualisation and analysing latent space. Might be slow, maybe take this out when live.\n",
    "        \n",
    "        Added MDN to increase variance of output as Bishop et al 1994. and Alemi et al 2017.\n",
    "        \n",
    "        MEED data only\n",
    "\n",
    "        All data, added 10% noise to emotions so model is less stuck. With LeakyRelu\n",
    "        Loss = mse_loss(keypoints) + mse_loss(emotions) because before output emotions ( which feature was added to keypoint features) were not being matched to input emotions\n",
    "        No penalty.\n",
    "\n",
    "        Added dropout to keypoints, also changed input to emotion linear to x and not just emotion (emotion + keypoints)\n",
    "        Taking extra dropout for emotions and keypoints out, because want model to rely on both equally so what's the point\n",
    "\n",
    "        dropout keypoints and dropout emotion is currently equal but might change this.\n",
    "\n",
    "        Emotions and keypoints are multimodal and added separately, but features are added in block processing using +.\n",
    "\n",
    "\n",
    "        Got rid of both L1 and L2, increasing dropout because model acting weird, this is now delta + coord. \n",
    "        Delta is between next frame and current frame. So current frame is previous coord+previous delta. Last frame's delta is 0. \n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "# If args are provided, use those; otherwise, parse from command line\n",
    "if args is None:\n",
    "    args = parse_args()\n",
    "\n",
    "# Set the global variables based on args\n",
    "set_globals(args)\n",
    "\n",
    "# Set global variables\n",
    "\n",
    "processed_data= prep_data(dataset=args.DATASET)\n",
    "# global train_data,train_emotions, val_data, val_emotions, frame_dim, max_x, min_x, max_y, min_y, max_dx, min_dx, max_dy, min_dy, threshold\n",
    "train_data, train_emotions, val_data, val_emotions, frame_dim, max_x, min_x, max_y, min_y, max_dx, min_dx, max_dy, min_dy, threshold = processed_data\n",
    "\n",
    "# create model\n",
    "# global m\n",
    "m = MotionModel(input_dim=frame_dim, output_dim=frame_dim,emotion_dim=7, blocksize=args.BLOCK_SIZE, hidden_dim=512, n_layers=8, dropout=args.DROPOUT)\n",
    "m = m.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=args.LEARNING_RATE, weight_decay=args.L2_REG)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "# Load the model\n",
    "print('Loading model...')\n",
    "\n",
    "\n",
    "m, optimizer, scheduler, epoch, loss, train_seed = load_checkpoint(m, optimizer, args.CHECKPOINT_PATH,scheduler)\n",
    "print(f\"Model {train_seed} loaded from {args.CHECKPOINT_PATH} (epoch {epoch}, loss {loss:.6f})\")\n",
    "\n",
    "\n",
    "# Functions\n",
    "def normalise_generated(unnorm_out, max_x, min_x, max_y, min_y, max_dx, min_dx, max_dy, min_dy): \n",
    "    norm_out = []\n",
    "    \n",
    "    for frame in unnorm_out:\n",
    "        norm_frame = []\n",
    "        \n",
    "        # Normalize the first 50 values (absolute x and y coordinates)\n",
    "        for i in range(0, 50, 2):\n",
    "            unnormalized_x = frame[i]\n",
    "            unnormalized_y = frame[i+1]\n",
    "            \n",
    "            norm_x = 2 * (unnormalized_x - min_x) / (max_x - min_x) - 1\n",
    "            norm_y = 2 * (unnormalized_y - min_y) / (max_y - min_y) - 1\n",
    "            \n",
    "            norm_frame.extend([norm_x, norm_y])\n",
    "        \n",
    "        # Normalize the second 50 values (x and y deltas)\n",
    "        for i in range(50, 100, 2):\n",
    "            unnormalized_dx = frame[i]\n",
    "            unnormalized_dy = frame[i+1]\n",
    "            \n",
    "            norm_dx = 2 * (unnormalized_dx - min_dx) / (max_dx - min_dx) - 1\n",
    "            norm_dy = 2 * (unnormalized_dy - min_dy) / (max_dy - min_dy) - 1\n",
    "            \n",
    "            norm_frame.extend([norm_dx, norm_dy])\n",
    "        \n",
    "        # Append the emotion encoding without normalizing\n",
    "    \n",
    "        norm_out.append(norm_frame)\n",
    "        \n",
    "    return norm_out\n",
    "\n",
    "\n",
    "# Initial setup\n",
    "shared_data = {\n",
    "    'average_scores': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "}\n",
    "\n",
    "# different from normal emotion labels - matches the sentiment analyser\n",
    "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
    "\n",
    "emotion_data = {emotion: {\"score\": 0.0, \"count\": 0} for emotion in emotion_labels}\n",
    "\n",
    "chat = pytchat.create(video_id=\"gCNeDWCI0vo\")\n",
    "FRAMES_GENERATE = 150\n",
    "terminate_threads = False\n",
    "\n",
    "# This queue will hold the batches ready for visualization\n",
    "viz_queue = queue.Queue()\n",
    "\n",
    "\n",
    "def process_chat_message(c):\n",
    "    \"\"\"Process a chat message and update emotion scores.\"\"\"\n",
    "    print(f\"{c.datetime} [{c.author.name}]- {c.message}\")\n",
    "    result = pipe(c.message)  # Assuming pipe() returns emotion prediction\n",
    "    print(result)\n",
    "\n",
    "    detected_emotion = result[0]['label']\n",
    "\n",
    "    # Reset the counter for the detected emotion and boost its score\n",
    "    emotion_data[detected_emotion][\"count\"] = 0\n",
    "    score = result[0]['score']\n",
    "    emotion_data[detected_emotion][\"score\"] = min(1, emotion_data[detected_emotion][\"score\"] + score)\n",
    "\n",
    "    # Decay scores for other emotions and increase their counters\n",
    "    for emotion, data in emotion_data.items():\n",
    "        if emotion != detected_emotion:\n",
    "            data[\"count\"] += 1\n",
    "            if data[\"count\"] >= 5:\n",
    "                data[\"score\"] = 0\n",
    "            else:\n",
    "                data[\"score\"] *= 0.5  # or any other decay factor you prefer\n",
    "\n",
    "    # Update average scores\n",
    "    for i, emotion in enumerate(emotion_labels):\n",
    "        shared_data['average_scores'][i] = emotion_data[emotion][\"score\"]\n",
    "\n",
    "    print(\"Average scores:\", shared_data['average_scores'])\n",
    "\n",
    "# Batch generation function\n",
    "def generate_new_batch(last_frame=None):\n",
    "    \"\"\"Generate a new batch based on the current average scores.\"\"\"\n",
    "    # If initial_data is None or empty, initialize with default values\n",
    "    if last_frame is None:\n",
    "        print('LAST FRAME IS NONE')\n",
    "        last_frame = torch.randn(1,5, 100).to(device)  # initialise with noise\n",
    "\n",
    "    last_frames = last_frame[0][-3:]\n",
    "    norm_last_frames = normalise_generated(last_frames, max_x, min_x, max_y, min_y, max_x, min_x, max_y, min_y)\n",
    "    new_input = torch.tensor([norm_last_frames]).to(device).float()\n",
    "    emotion_in = torch.tensor([shared_data['average_scores']]).to(device).float()\n",
    "\n",
    "    # Generate the new frames\n",
    "    generated_keypoints, generated_emotion = m.generate(new_input, emotion_in, FRAMES_GENERATE)\n",
    "    \n",
    "    emotion_vectors = (emotion_in, generated_emotion)\n",
    "    return unnormalise_list_2D(generated_keypoints, max_x, min_x, max_y, min_y, max_x, min_x, max_y, min_y), emotion_vectors\n",
    "\n",
    "def generate_batches_periodically(period=2, last_frame=None):\n",
    "    # initialise with last_frame = None\n",
    "    while not terminate_threads:  \n",
    "        time.sleep(period)\n",
    "        unnorm_out, emotion_vectors = generate_new_batch(last_frame)\n",
    "        viz_queue.put((unnorm_out, emotion_vectors))  \n",
    "        last_frame = unnorm_out\n",
    "        \n",
    "\n",
    "def visualise(unnorm_out, emotion_vectors):\n",
    "    # visualize\n",
    "    emotion_in, generated_emotion = emotion_vectors \n",
    "    emotion_vectors = (emotion_in[0], generated_emotion[0]) #quick fix\n",
    "    \n",
    "    visualise_skeleton(unnorm_out[0], max_x, max_y, emotion_vectors,max_frames=FRAMES_GENERATE,save = False,save_path=None,prefix=f'{EPOCHS}_main_test',train_seed=train_seed,delta=False,destroy=False)\n",
    "\n",
    "def visualise_batches():\n",
    "    while not terminate_threads:  # Check the global termination flag\n",
    "        batch = viz_queue.get()  # Get the tuple from the queue\n",
    "        if batch is None:  # Check if the thread should terminate\n",
    "            break\n",
    "        unnorm_out, emotion_vectors = batch  # Unpack the tuple\n",
    "        visualise(unnorm_out, emotion_vectors)\n",
    "\n",
    "# Start the threads\n",
    "visualisation_thread = threading.Thread(target=visualise_batches, daemon=True)\n",
    "generation_thread = threading.Thread(target=generate_batches_periodically, args=(10,), daemon=True)\n",
    "\n",
    "visualisation_thread.start()\n",
    "generation_thread.start()\n",
    "\n",
    "\n",
    "# Process chat messages\n",
    "while chat.is_alive():\n",
    "    if keyboard.is_pressed('esc'):  # Check if ESC key is pressed\n",
    "        terminate_threads = True\n",
    "        viz_queue.put(None)  # Put a None in the queue to signal the visualisation thread to terminate\n",
    "        break  # Exit the main loop\n",
    "    for c in chat.get().sync_items():\n",
    "        process_chat_message(c)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Wait for threads to finish if needed\n",
    "visualisation_thread.join()\n",
    "generation_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "GLError",
     "evalue": "GLError(\n\terr = 1282,\n\tdescription = b'invalid operation',\n\tbaseOperation = glRotatef,\n\tcArguments = (1, 3, 1, 1)\n)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGLError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\\main.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         pygame\u001b[39m.\u001b[39mtime\u001b[39m.\u001b[39mwait(\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\avika\\OneDrive\\Documents\\UAL\\interactive_dance_thesis\\main.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m         pygame\u001b[39m.\u001b[39mquit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         quit()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m glRotatef(\u001b[39m1\u001b[39;49m, \u001b[39m3\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m glClear(GL_COLOR_BUFFER_BIT\u001b[39m|\u001b[39mGL_DEPTH_BUFFER_BIT)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/avika/OneDrive/Documents/UAL/interactive_dance_thesis/main.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m obj\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32msrc/errorchecker.pyx:58\u001b[0m, in \u001b[0;36mOpenGL_accelerate.errorchecker._ErrorChecker.glCheckError\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mGLError\u001b[0m: GLError(\n\terr = 1282,\n\tdescription = b'invalid operation',\n\tbaseOperation = glRotatef,\n\tcArguments = (1, 3, 1, 1)\n)"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "from pygame.locals import *\n",
    "from OpenGL.GL import *\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU import *\n",
    "\n",
    "class OBJ:\n",
    "    def __init__(self, filename):\n",
    "        self.vertices = []\n",
    "        self.faces = []\n",
    "        self.load_obj(filename)\n",
    "\n",
    "    def load_obj(self, filename):\n",
    "        for line in open(filename, \"r\"):\n",
    "            if line.startswith('#'): continue\n",
    "            values = line.split()\n",
    "            if not values: continue\n",
    "\n",
    "            if values[0] == 'v':\n",
    "                self.vertices.append(list(map(float, values[1:4])))\n",
    "            elif values[0] == 'f':\n",
    "                face = []\n",
    "                for v in values[1:]:\n",
    "                    w = v.split('/')\n",
    "                    face.append(int(w[0]))\n",
    "                self.faces.append(face)\n",
    "\n",
    "    def render(self):\n",
    "        glBegin(GL_TRIANGLES)\n",
    "        for face in self.faces:\n",
    "            for vertex in face:\n",
    "                glVertex3fv(self.vertices[vertex - 1])\n",
    "        glEnd()\n",
    "\n",
    "def main():\n",
    "    pygame.init()\n",
    "    display = (800,600)\n",
    "    pygame.display.set_mode(display, DOUBLEBUF|OPENGL)\n",
    "    gluPerspective(45, (display[0]/display[1]), 0.1, 50.0)\n",
    "    glTranslatef(0.0,0.0, -5)\n",
    "\n",
    "    obj = OBJ(\"data/human_mesh.obj\")  # Replace 'yourmodel.obj' with your file name\n",
    "\n",
    "    while True:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                quit()\n",
    "\n",
    "        glRotatef(1, 3, 1, 1)\n",
    "        glClear(GL_COLOR_BUFFER_BIT|GL_DEPTH_BUFFER_BIT)\n",
    "        obj.render()\n",
    "        pygame.display.flip()\n",
    "        pygame.time.wait(10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interactive_dance_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
